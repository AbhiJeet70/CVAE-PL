{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 37705,
          "sourceType": "datasetVersion",
          "datasetId": 29561
        },
        {
          "sourceId": 3450962,
          "sourceType": "datasetVersion",
          "datasetId": 2078533
        },
        {
          "sourceId": 8160279,
          "sourceType": "datasetVersion",
          "datasetId": 4827773
        }
      ],
      "dockerImageVersionId": 30176,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Perceptual Loss in VAE",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhiJeet70/PerceptualLossVAE/blob/main/Perceptual_Loss_in_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'celeba-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F29561%2F37705%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240503%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240503T211638Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D44933434f7f6976a174955c00dc35e1380278abc2ca6e7197e6092fe672ce8a4de6f84d25a8f4367e22d956c6821c8e4405d2ed5ab21f120d0d30b86e4fd8590b31a1f7de480ee757444febea3bf78d3c759017837e1313c7c9969a58678ed153acb3eb52faab2c1555a08169ce2f50725d962fcf9796b4714e25ea5e4e5faba6b05a55f7edae4ac99e84fa0b99b64c97929880ce2b05458fd2344332357751a04c42dd91ab715effcd868cfd6b03508ed989692b155c3f76296a1592d07a38bc9d5e7df95530ffdcbfb999c6fac5e3eab9a03d7feed25b15cd0d4fae7befcd62596302ce83e17b3f1291757daa8064477a891670a7c29b45a82a70bc99a4bd2,celeba-small-images-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2078533%2F3450962%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240503%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240503T211638Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D78725995b0b743cd9b0cbcc6ff9d5f80d9d1cec33aec297800b6f6bf132e3fe937e833192a78a8ebb240ee18565e5ffc990abde7158cd1fb2d5a8ec2ef86256d4b7f07314d70dd51e6091e62f451802ce10bb066210cdfe2c0e859e51ce6a25a82ca1ed806164a799de72a95037c1ef428db6be616036f3a7622ed4464dc8280ec4b3cb5e92e29d27e5535c8de707a99a53e2139daeac8141df2f9c42c109478a64c0ec8ec89185a1780877ad25047a301a3fb86764911ea6500a2514f274a71963a220727b59a05621e361f7d6c28fc5369899bc4d026a76688721f55f907294fc94ac6e3eae3b5ba555ba1f4eb7e4619514fc12e5b99733611efd988c7d632,vgg19-weights:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4827773%2F8160279%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240503%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240503T211638Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D21093dc203458d7d7cfdb439d1a253f612dc7a814b80337d27244a8a76850987787b3838df5af8816bcf1f0eb9f930e8dc87792d43addf755adc80d0d1261cfe75d5b72ba76263273af9d8ac95e19b3b3e7d64c065e1d6cab2e88f32a560eb581b5178759902f2ae0933f39c3e3b0c3476c59e6c527b4f5eb043f14e63cde3f8f514cc7a0d4e85151a8d570ca809a980ef07760eab21b51bb1fb1e365a2eb66dacc33c2b320b0361c63d1e2b941e5d9cb43dd63facfc799eb9d2e04bcdc56da3223f9daa750213451cae704b187cab0c089588302dd7772fbceed17d6d3921f3afe5bcd7aa561eb3989e33070f6ec5a44718cc8eb3596e583d951eba4533c8eb'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "0uo91eGPURQh"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os, warnings\n",
        "import json\n",
        "import datetime\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import layers\n",
        "from keras import backend\n",
        "from keras import utils\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.layers import CenterCrop\n",
        "from tensorflow.keras.layers import Resizing\n",
        "from tensorflow.keras.layers import Rescaling\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler,ReduceLROnPlateau,ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "\n",
        "# Disable TensorFlow info and warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "# Constants :\n",
        "batch_size = 64\n",
        "img_path = '/kaggle/input/celeba-small-images-dataset/'"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-05-02T03:45:56.033932Z",
          "iopub.execute_input": "2024-05-02T03:45:56.034326Z",
          "iopub.status.idle": "2024-05-02T03:46:01.808081Z",
          "shell.execute_reply.started": "2024-05-02T03:45:56.034224Z",
          "shell.execute_reply": "2024-05-02T03:46:01.807176Z"
        },
        "trusted": true,
        "id": "w7yjbArBURQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A short function that converts a file path to an (img, label) pair\n",
        "# with label is the img itself as our model is an autoencoder.\n",
        "def process_path(file_path):\n",
        "  # Load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = tf.io.decode_jpeg(img, channels=3)\n",
        "  #return img, img\n",
        "  return img\n",
        "\n",
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.batch(batch_size, drop_remainder=True)\n",
        "  ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "train_ds = tf.data.Dataset.list_files(img_path + 'training/*.jpg', shuffle=False)\n",
        "val_ds = tf.data.Dataset.list_files(img_path + 'validation/*.jpg', shuffle=False)\n",
        "test_ds = tf.data.Dataset.list_files(img_path + 'testing/*.jpg', shuffle=False)\n",
        "\n",
        "# Use Dataset.map to create a dataset of image, label pairs:\n",
        "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
        "train_ds = train_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "train_ds = configure_for_performance(train_ds)\n",
        "val_ds = configure_for_performance(val_ds)\n",
        "test_ds = configure_for_performance(test_ds)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2024-05-02T03:46:01.809704Z",
          "iopub.execute_input": "2024-05-02T03:46:01.809965Z",
          "iopub.status.idle": "2024-05-02T03:56:17.089655Z",
          "shell.execute_reply.started": "2024-05-02T03:46:01.809935Z",
          "shell.execute_reply": "2024-05-02T03:56:17.089003Z"
        },
        "trusted": true,
        "id": "MzRHfowaURQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#display a few celebrity faces\n",
        "plt.figure(figsize=(10, 5))\n",
        "#for image_batch, label_batch in train_ds.take(1):\n",
        "for image_batch in train_ds.take(1):\n",
        "    for i in range(10):\n",
        "        ax = plt.subplot(2, 5, i + 1)\n",
        "        plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
        "        plt.axis(\"off\")\n",
        "plt.show();"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-02T03:56:17.093143Z",
          "iopub.execute_input": "2024-05-02T03:56:17.093407Z",
          "iopub.status.idle": "2024-05-02T03:56:17.784012Z",
          "shell.execute_reply.started": "2024-05-02T03:56:17.093376Z",
          "shell.execute_reply": "2024-05-02T03:56:17.78309Z"
        },
        "trusted": true,
        "id": "FmBh285jURQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the image preprocesser\n",
        "def create_preprocesser():\n",
        "\n",
        "    inputs = keras.Input(shape=(64,64,3))\n",
        "\n",
        "    preprocessed = Rescaling(1./255)(inputs)\n",
        "\n",
        "    preprocesser = Model(inputs,preprocessed, name='preprocesser')\n",
        "\n",
        "    return preprocesser"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-02T03:56:17.785666Z",
          "iopub.execute_input": "2024-05-02T03:56:17.785888Z",
          "iopub.status.idle": "2024-05-02T03:56:17.790284Z",
          "shell.execute_reply.started": "2024-05-02T03:56:17.785861Z",
          "shell.execute_reply": "2024-05-02T03:56:17.789509Z"
        },
        "trusted": true,
        "id": "oHoxMYRrURQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the encoder\n",
        "def create_encoder():\n",
        "\n",
        "    inputs = keras.Input(shape=(64,64,3))\n",
        "\n",
        "    # 32x4x4 conv, stride 2 + BN + LeakyReLU\n",
        "    x = layers.Conv2D(32,(4, 4), strides=2, padding='same', activation=None)(inputs)\n",
        "    x = layers.BatchNormalization(axis=-1)(x) # axis=-1 as data format is 'channels_last' and we want to normalize each channel\n",
        "    x = layers.LeakyReLU(alpha=0.3)(x)\n",
        "\n",
        "    #64x4x4 conv, stride 2 + BN + LeakyReLU\n",
        "    x = layers.Conv2D(64,(4, 4), strides=2, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    #128x4x4 conv, stride 2 + BN + LeakyReLU\n",
        "    x = layers.Conv2D(128,(4, 4), strides=2, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    #256x4x4 conv, stride 2 + BN + LeakyReLU\n",
        "    x = layers.Conv2D(256,(4, 4), strides=2, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    # flatten the output\n",
        "    x = layers.Flatten(data_format='channels_last')(x)\n",
        "\n",
        "    # distribution parameters\n",
        "    z_mean = layers.Dense(units=100, activation=None)(x)\n",
        "    z_log_sigma = layers.Dense(units=100, activation=None)(x)\n",
        "\n",
        "    # use these parameters to sample new similar points from the latent space:\n",
        "    def sampling(args):\n",
        "        z_mean, z_log_sigma = args\n",
        "        epsilon = backend.random_normal(shape=(1, 100), mean=0., stddev=0.1)\n",
        "        #epsilon = backend.random_normal(shape=(1, 100), mean=0., stddev=1.)\n",
        "        return z_mean + backend.exp(z_log_sigma / 2) * epsilon\n",
        "\n",
        "    z = layers.Lambda(sampling)([z_mean, z_log_sigma])\n",
        "\n",
        "    # Create encoder\n",
        "    encoder = Model(inputs,[z_mean, z_log_sigma, z], name='encoder')\n",
        "    #encoder.summary()\n",
        "\n",
        "    return encoder"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-02T03:56:17.791483Z",
          "iopub.execute_input": "2024-05-02T03:56:17.791744Z",
          "iopub.status.idle": "2024-05-02T03:56:17.804318Z",
          "shell.execute_reply.started": "2024-05-02T03:56:17.791709Z",
          "shell.execute_reply": "2024-05-02T03:56:17.803472Z"
        },
        "trusted": true,
        "id": "LYt7YfyGURQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the decoder\n",
        "def create_decoder():\n",
        "\n",
        "    inputs = keras.Input(shape=(100))\n",
        "\n",
        "    x = layers.Dense(units=4096, activation='relu')(inputs)\n",
        "    x = layers.Reshape((4,4,256))(x)\n",
        "\n",
        "    # upsample + conv128x3x3 + BN + LeakyReLU\n",
        "    x = layers.UpSampling2D((2,2), data_format='channels_last', interpolation='nearest')(x)\n",
        "    x = layers.Conv2D(128,(3, 3), padding='same', strides=(1,1))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    # upsample + conv64x3x3 + BN + LeakyReLU\n",
        "    x = layers.UpSampling2D((2,2))(x)\n",
        "    x = layers.Conv2D(64,(3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    # upsample + conv32x3x3 + BN + LeakyReLU\n",
        "    x = layers.UpSampling2D((2,2))(x)\n",
        "    x = layers.Conv2D(32,(3, 3), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    # upsample + conv128x3x3\n",
        "    x = layers.UpSampling2D((2,2))(x)\n",
        "    decoded = layers.Conv2D(3,(3, 3), padding='same')(x)\n",
        "\n",
        "    decoder = Model(inputs, decoded, name='decoder')\n",
        "    return decoder"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-02T03:56:17.805564Z",
          "iopub.execute_input": "2024-05-02T03:56:17.805826Z",
          "iopub.status.idle": "2024-05-02T03:56:17.816399Z",
          "shell.execute_reply.started": "2024-05-02T03:56:17.805743Z",
          "shell.execute_reply": "2024-05-02T03:56:17.815692Z"
        },
        "trusted": true,
        "id": "77e7DqdOURQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build and Train the Plain VAE\n",
        "class PVAE(keras.Model):\n",
        "\n",
        "    def __init__(self, preprocesser, encoder, decoder, alpha, beta, **kwargs):\n",
        "        super(PVAE, self).__init__(**kwargs)\n",
        "        self.preprocesser = preprocesser\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "        self.loss_wo_weight_tracker = keras.metrics.Mean(name=\"loss_wo_weight\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.loss_tracker,\n",
        "            self.loss_wo_weight_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def forward(self, data):\n",
        "        # Forward pass\n",
        "        preprocessed = self.preprocesser(data)\n",
        "        z_mean, z_log_sigma, z = self.encoder(preprocessed)\n",
        "        reconstruction = self.decoder(z)\n",
        "        return z_mean, z_log_sigma,reconstruction\n",
        "\n",
        "    def compute_loss(self, data, z_mean, z_log_sigma, reconstruction):\n",
        "        reconstruction_loss = tf.reduce_mean(keras.losses.mean_squared_error(data, reconstruction))\n",
        "        kl_loss = -0.5 * (1 + z_log_sigma - tf.square(z_mean) - tf.exp(z_log_sigma))\n",
        "        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "        loss_wo_weight = reconstruction_loss + kl_loss\n",
        "        loss = self.alpha * reconstruction_loss + self.beta * kl_loss\n",
        "        return reconstruction_loss, kl_loss, loss, loss_wo_weight\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass\n",
        "            z_mean, z_log_sigma, reconstruction = self.forward(data)\n",
        "            # Compute the loss value\n",
        "            reconstruction_loss, kl_loss, loss, loss_wo_weight = self.compute_loss(data, z_mean, z_log_sigma, reconstruction)\n",
        "        # Compute gradients\n",
        "        grads = tape.gradient(loss, self.trainable_variables)\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
        "        # Update metrics (metrics = losses in our case)\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.loss_wo_weight_tracker.update_state(loss_wo_weight)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        # Return metrics\n",
        "        return {\n",
        "            \"loss\": self.loss_tracker.result(),\n",
        "            \"loss_wo_weight\": self.loss_wo_weight_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n",
        "\n",
        "    def call(self, data):\n",
        "        # Forward pass\n",
        "        z_mean, z_log_sigma, reconstruction = self.forward(data)\n",
        "        # Compute the loss value\n",
        "        reconstruction_loss, kl_loss, loss, loss_wo_weight = self.compute_loss(data, z_mean, z_log_sigma, reconstruction)\n",
        "        # Update metrics (metrics = losses in our case)\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.loss_wo_weight_tracker.update_state(loss_wo_weight)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        # Return metrics\n",
        "        return {\n",
        "            \"loss\": self.loss_tracker.result(),\n",
        "            \"loss_wo_weight\": self.loss_wo_weight_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "            \"reconstruction\":reconstruction,\n",
        "        }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-02T03:56:17.817565Z",
          "iopub.execute_input": "2024-05-02T03:56:17.817817Z",
          "iopub.status.idle": "2024-05-02T03:56:17.835955Z",
          "shell.execute_reply.started": "2024-05-02T03:56:17.817787Z",
          "shell.execute_reply": "2024-05-02T03:56:17.835151Z"
        },
        "trusted": true,
        "id": "Vq1n0iR7URQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for losses\n",
        "def display_history(history):\n",
        "\n",
        "    fig=plt.figure(figsize=(20,5))\n",
        "\n",
        "    ax = plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['reconstruction_loss'])\n",
        "    plt.plot(history.history['val_reconstruction_loss'])\n",
        "    plt.title('reconstruction_loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "    ax = plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['kl_loss'])\n",
        "    plt.plot(history.history['val_kl_loss'])\n",
        "    plt.title('kl_loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-05-02T03:56:17.837147Z",
          "iopub.execute_input": "2024-05-02T03:56:17.837436Z",
          "iopub.status.idle": "2024-05-02T03:56:17.848362Z",
          "shell.execute_reply.started": "2024-05-02T03:56:17.837391Z",
          "shell.execute_reply": "2024-05-02T03:56:17.847595Z"
        },
        "trusted": true,
        "id": "_T5mu6bSURQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 1.8\n",
        "beta = 10\n",
        "lr = 0.0015\n",
        "\n",
        "ppreprocesser = create_preprocesser()\n",
        "pencoder = create_encoder()\n",
        "pdecoder = create_decoder()\n",
        "pvae = PVAE(ppreprocesser, pencoder, pdecoder, alpha, beta)\n",
        "pvae.compile(optimizer=keras.optimizers.Adam(lr))\n",
        "\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(monitor='val_loss_wo_weight', factor=0.2, patience=2, verbose=1, mode='min'),\n",
        "    ModelCheckpoint(filepath='./pvae/', monitor=\"val_loss_wo_weight\", verbose=1, save_best_only=True)\n",
        "]\n",
        "history_pvae = pvae.fit(x=train_ds, epochs=30, validation_data=val_ds, batch_size=batch_size, callbacks=callbacks)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2024-05-02T03:56:17.849482Z",
          "iopub.execute_input": "2024-05-02T03:56:17.849738Z",
          "iopub.status.idle": "2024-05-02T06:47:10.132082Z",
          "shell.execute_reply.started": "2024-05-02T03:56:17.849708Z",
          "shell.execute_reply": "2024-05-02T06:47:10.131214Z"
        },
        "trusted": true,
        "id": "k8UQSx5MURQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_history(history_pvae)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2024-05-02T06:47:10.144271Z",
          "iopub.execute_input": "2024-05-02T06:47:10.144711Z",
          "iopub.status.idle": "2024-05-02T06:47:10.515703Z",
          "shell.execute_reply.started": "2024-05-02T06:47:10.144677Z",
          "shell.execute_reply": "2024-05-02T06:47:10.514999Z"
        },
        "trusted": true,
        "id": "r9A4Sv6jURQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build and Train the VAE with Perceptual Loss\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "\n",
        "class VAE_123(keras.Model):\n",
        "\n",
        "    def __init__(self, preprocesser, encoder, decoder, alpha, beta, vgg19_123, **kwargs):\n",
        "        super(VAE_123, self).__init__(**kwargs)\n",
        "        self.preprocesser = preprocesser\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.vgg19_123 = vgg19_123\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "        self.loss_wo_weight_tracker = keras.metrics.Mean(name=\"loss_wo_weight\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.loss_tracker,\n",
        "            self.loss_wo_weight_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        preprocessed = self.preprocesser(inputs)\n",
        "        z_mean, z_log_sigma, z = self.encoder(preprocessed)\n",
        "        reconstruction = self.decoder(z)\n",
        "        if training:\n",
        "            return self.compute_loss(inputs, z_mean, z_log_sigma, reconstruction)\n",
        "        else:\n",
        "            return reconstruction\n",
        "\n",
        "    def compute_loss(self, data, z_mean, z_log_sigma, reconstruction):\n",
        "        data = preprocess_input(data)\n",
        "        reconstruction = preprocess_input(reconstruction)\n",
        "        vgg19_data_1, vgg19_data_2, vgg19_data_3 = self.vgg19_123(data)\n",
        "        vgg19_rec_1, vgg19_rec_2, vgg19_rec_3 = self.vgg19_123(reconstruction)\n",
        "        reconstruction_loss_1 = tf.reduce_mean(keras.losses.mean_squared_error(vgg19_data_1, vgg19_rec_1))\n",
        "        reconstruction_loss_2 = tf.reduce_mean(keras.losses.mean_squared_error(vgg19_data_2, vgg19_rec_2))\n",
        "        reconstruction_loss = (reconstruction_loss_1 + reconstruction_loss_2) / 2\n",
        "        kl_loss = -0.5 * (1 + z_log_sigma - tf.square(z_mean) - tf.exp(z_log_sigma))\n",
        "        kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "        loss_wo_weight = reconstruction_loss + kl_loss\n",
        "        loss = self.alpha * reconstruction_loss + self.beta * kl_loss\n",
        "        return {\"loss\": loss, \"loss_wo_weight\": loss_wo_weight, \"reconstruction_loss\": reconstruction_loss, \"kl_loss\": kl_loss}\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss_values = self.call(data, training=True)\n",
        "            loss = loss_values[\"loss\"]\n",
        "        grads = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
        "        return loss_values\n",
        "\n",
        "    def test_step(self, data):\n",
        "        loss_values = self.call(data, training=True)\n",
        "        return loss_values\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-02T06:47:10.517188Z",
          "iopub.execute_input": "2024-05-02T06:47:10.517609Z",
          "iopub.status.idle": "2024-05-02T06:47:10.536548Z",
          "shell.execute_reply.started": "2024-05-02T06:47:10.517564Z",
          "shell.execute_reply": "2024-05-02T06:47:10.535451Z"
        },
        "trusted": true,
        "id": "gQvFY2qpURQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 1.8\n",
        "beta = 10\n",
        "lr = 0.0015\n",
        "\n",
        "vgg19 = VGG19(include_top=False, weights='/kaggle/input/vgg19-weights/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5', input_shape=(64, 64, 3))\n",
        "vgg19_123 = Model(inputs=vgg19.input, outputs=[vgg19.get_layer('block1_conv1').output, vgg19.get_layer('block2_conv1').output, vgg19.get_layer('block3_conv1').output])\n",
        "vgg19_123.trainable = False\n",
        "\n",
        "preprocesser_123 = create_preprocesser()\n",
        "encoder_123 = create_encoder()\n",
        "decoder_123 = create_decoder()\n",
        "vae_123 = VAE_123(preprocesser_123, encoder_123, decoder_123, alpha, beta, vgg19_123)\n",
        "vae_123.compile(optimizer=keras.optimizers.Adam(lr), run_eagerly=True)\n",
        "\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(monitor='val_loss_wo_weight', factor=0.2, patience=2, verbose=1, mode='min'),\n",
        "    ModelCheckpoint(filepath='./vae_123/', monitor=\"val_loss_wo_weight\", verbose=1, save_best_only=True)\n",
        "]\n",
        "history_123 = vae_123.fit(x=train_ds, epochs=30, validation_data=val_ds, batch_size=batch_size, callbacks=callbacks)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-02T06:47:10.538429Z",
          "iopub.execute_input": "2024-05-02T06:47:10.538701Z"
        },
        "trusted": true,
        "id": "xaUDyxldURQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_history(history_123)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "k-PTVcdwURQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reconstruction\n",
        "test_ds_reconstructed_p = pvae.predict(test_ds)\n",
        "test_ds_reconstructed_p = test_ds_reconstructed_p['reconstruction']\n",
        "test_ds_reconstructed_123 = vae_123.predict(test_ds)\n",
        "test_ds_reconstructed_123 = test_ds_reconstructed_123['reconstruction']"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "stS3v5SnURQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_rec_images(test_ds_reconstructed):\n",
        "\n",
        "    images = ['182638.jpg','182639.jpg','182640.jpg','182641.jpg','182642.jpg']\n",
        "\n",
        "    fig=plt.figure(figsize=(20,5))\n",
        "\n",
        "    for i in range(0,5):\n",
        "\n",
        "        #display original image\n",
        "        f = img_path + 'testing/' + images[i]\n",
        "        img = PIL.Image.open(f)\n",
        "\n",
        "        ax = plt.subplot(2, 5, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "\n",
        "        #display reconstructed image\n",
        "        ax = plt.subplot(2, 5, i + 6)\n",
        "        plt.imshow(test_ds_reconstructed[i].astype(\"uint8\"))\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "EmOPs5WdURQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Celebrity faces reconstructed using the Plain VAE (top : original images, bottom : reconstructed images)\n",
        "display_rec_images(test_ds_reconstructed_p)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "sHc97Y4hURQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Celebrity faces reconstructed using VAE_123 :\n",
        "display_rec_images(test_ds_reconstructed_123)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "ogwCtZpxURQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate new face images\n",
        "def display_fake_images(decoder):\n",
        "    z = np.random.normal(loc=0.0, scale=0.5, size=(10,100,1))\n",
        "    fakefaces = decoder(z)\n",
        "\n",
        "    plt.figure(figsize=(20, 5))\n",
        "    for i in range(0, len(fakefaces)):\n",
        "        ax = plt.subplot(2, 5, i + 1)\n",
        "        plt.imshow(fakefaces[i].numpy().astype(\"uint8\"))\n",
        "        plt.axis(\"off\")\n",
        "    plt.show();"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "vA_QidRbURQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from the decoder network of plain variational autoencoder (PVAE) trained with pixel-based loss\n",
        "display_fake_images(pdecoder)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "9KOLFiy8URQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from the decoder network of plain variational autoencoder (VAE_123) trained with perceptual loss\n",
        "display_fake_images(decoder_123)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "buG6WE-IURQy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}